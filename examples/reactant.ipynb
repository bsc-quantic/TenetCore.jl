{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6f9952a",
   "metadata": {},
   "source": [
    "# Reactant.jl integration\n",
    "\n",
    "Reactant.jl is a Julia frontend to the MLIR framework and XLA compiler. It takes Julia code, optimizes aggresively and compiles to CPU / GPU / TPU / distributed clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df94ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using TenetCore\n",
    "using Reactant\n",
    "using Adapt\n",
    "using Random\n",
    "using Chairmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "483bec0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericTensorNetwork (#tensors=4, #inds=6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Random.seed!(1234)\n",
    "tn = rand(TensorNetwork, 4, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90a450",
   "metadata": {},
   "source": [
    "Reactant.jl traces the use of its own array types; i.e. it only tracks the operations performed on `Reactant.ConcreteRArray`s.\n",
    "\n",
    "So first, the arrays of tensors in the Tensor Network need to be converted to `ConcreteRArray`. This is easily done with `Adapt.adapt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd7c8594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericTensorNetwork (#tensors=4, #inds=6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tnre = adapt(ConcreteRArray, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d61ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: before\n",
      "│   typeof((tensors(tn))[1]) = Tensor{Float64, 6, Array{Float64, 6}}\n",
      "└ @ Main /Users/mofeing/Developer/TenetCore.jl/examples/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X10sZmlsZQ==.jl:1\n",
      "┌ Info: after\n",
      "│   typeof((tensors(tnre))[1]) = Tensor{Float64, 6, ConcretePJRTArray{Float64, 6, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}}\n",
      "└ @ Main /Users/mofeing/Developer/TenetCore.jl/examples/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X10sZmlsZQ==.jl:2\n"
     ]
    }
   ],
   "source": [
    "@info \"before\" typeof(tensors(tn)[1])\n",
    "@info \"after\" typeof(tensors(tnre)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a749ee",
   "metadata": {},
   "source": [
    "`Reactant.compile` compiles the given code using the compilers mentioned above and returns a _thunk_ (a _functor_, a callable object). The thunk accepts the same type of arguments as the ones passed to `Reactant.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37793865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-dimensional Tensor{Float64, 0, ConcretePJRTArray{Float64, 0, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}}:\n",
       "1291.8407836130243"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = Reactant.compile(TenetCore.contract, (tnre,))\n",
    "f(tnre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c422be",
   "metadata": {},
   "source": [
    "`@compile` is a helper macro for `Reactant.compile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b0b5346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-dimensional Tensor{Float64, 0, ConcretePJRTArray{Float64, 0, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}}:\n",
       "1291.8407836130243"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = @compile TenetCore.contract(tnre)\n",
    "f(tnre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539efb17",
   "metadata": {},
   "source": [
    "`@jit` is a helper macro that is equivalent to `@compile` plus directly calling the compiled function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0c38d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-dimensional Tensor{Float64, 0, ConcretePJRTArray{Float64, 0, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}}:\n",
       "1291.8407836130243"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@jit TenetCore.contract(tnre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2605cdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.125 μs (46 allocs: 1.562 KiB)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@b f(tnre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9be36d",
   "metadata": {},
   "source": [
    "## Inspecting what's happenning under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f955f43",
   "metadata": {},
   "source": [
    "Just like with Julia's `@code_lowered`, `@code_llvm`, `@code_native`, ... introspection tools, Reactant.jl provides the `@code_hlo`, `@code_mhlo` and `@code_xla` tools to inspect the emitted MLIR and HLO code.\n",
    "\n",
    "Despite its name, `@code_hlo` prints the MLIR representation of the code, which is the main representation Reactant.jl works with. For example, the MLIR code of the compiled contraction is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b170c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "module @reactant_contract attributes {mhlo.num_partitions = 1 : i64, mhlo.num_replicas = 1 : i64} {\n",
       "  func.func @main(%arg0: tensor<7x6x7x8x5x2xf64>, %arg1: tensor<2x7xf64>, %arg2: tensor<6x7xf64>, %arg3: tensor<5x8xf64>) -> tensor<f64> {\n",
       "    %0 = stablehlo.transpose %arg0, dims = [5, 4, 3, 2, 1, 0] : (tensor<7x6x7x8x5x2xf64>) -> tensor<2x5x8x7x6x7xf64>\n",
       "    %1 = stablehlo.transpose %arg1, dims = [1, 0] : (tensor<2x7xf64>) -> tensor<7x2xf64>\n",
       "    %2 = stablehlo.transpose %arg2, dims = [1, 0] : (tensor<6x7xf64>) -> tensor<7x6xf64>\n",
       "    %3 = stablehlo.transpose %arg3, dims = [1, 0] : (tensor<5x8xf64>) -> tensor<8x5xf64>\n",
       "    %4 = stablehlo.dot_general %0, %2, contracting_dims = [3, 4] x [0, 1], precision = [DEFAULT, DEFAULT] : (tensor<2x5x8x7x6x7xf64>, tensor<7x6xf64>) -> tensor<2x5x8x7xf64>\n",
       "    %5 = stablehlo.dot_general %4, %3, contracting_dims = [1, 2] x [1, 0], precision = [DEFAULT, DEFAULT] : (tensor<2x5x8x7xf64>, tensor<8x5xf64>) -> tensor<2x7xf64>\n",
       "    %6 = stablehlo.dot_general %1, %5, contracting_dims = [0, 1] x [1, 0], precision = [DEFAULT, DEFAULT] : (tensor<7x2xf64>, tensor<2x7xf64>) -> tensor<f64>\n",
       "    return %6 : tensor<f64>\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@code_hlo TenetCore.contract(tnre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca897450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
